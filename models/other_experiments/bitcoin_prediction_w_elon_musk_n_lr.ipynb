{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Price Trend Prediction with VADER and Logistic Regression\n",
    "In this jupiter notebook, we experienment the approach to predict the bitcoin price trend using features like sentiment score and label, number of comments, likes, reweets.\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to get the sentiment score and sentiment label of a text using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score_and_label(text):\n",
    "  # VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool\n",
    "  # that is specifically attuned to sentiments expressed in social media.\n",
    "  analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "  # Analyze sentiment\n",
    "  scores = analyzer.polarity_scores(text)\n",
    "\n",
    "  score = scores['compound']\n",
    "  # positive sentiment : (compound score >= 0.05) \n",
    "  if score >= 0.05:\n",
    "    label = 1\n",
    "  # negative sentiment : (compound score <= -0.05)\n",
    "  elif score <= -0.05:\n",
    "    label = -1\n",
    "  # neutral sentiment : (compound score > -0.05) and (compound score < 0.05) \n",
    "  else:\n",
    "    label = 0\n",
    "  return score, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to get the price trend label\n",
    "Check the percentage difference between the prices of when the tweet was published and 15 mins after the tweet was published.\n",
    "1. If the percentage difference >= 1%, label as 1 (increase)\n",
    "2. If the percentage difference <= -1%, label as -1 (decrease)\n",
    "3. Otherwise, label as 0 (no change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_trend_label(prices):\n",
    "  prices_list = eval(prices)\n",
    "  first_price = prices_list[0]\n",
    "  last_price = prices_list[-1]\n",
    "\n",
    "  price_difference = last_price - first_price\n",
    "  percentage_difference = (price_difference / first_price) * 100\n",
    "\n",
    "  if percentage_difference >= 1:\n",
    "    print(\"increase by 1%\", first_price, last_price)\n",
    "    return 1 # increase\n",
    "  elif percentage_difference <= -1:\n",
    "    print(\"decrease by 1%\", first_price, last_price)\n",
    "    return -1 # decrease\n",
    "  else:\n",
    "    return 0 # no change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to clean up numbers in Elon Tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_number(num_str_origin, text):\n",
    "    if num_str_origin == 'nan':\n",
    "        return 0\n",
    "    \n",
    "    # Remove any commas from the string\n",
    "    num_str = num_str_origin.replace(',', '')\n",
    "    \n",
    "    # Extract the numerical value\n",
    "    num = re.findall(r'\\d+\\.?\\d*', num_str)\n",
    "    \n",
    "    # If K (thousand) is present, multiply by 1000\n",
    "    if 'K' in num_str:\n",
    "        return int(float(num[0]) * 1000)\n",
    "    \n",
    "    # If M (million) is present, multiply by 1000000\n",
    "    elif 'M' in num_str:\n",
    "        return int(float(num[0]) * 1000000)\n",
    "    \n",
    "    # Otherwise, return the number\n",
    "    else:\n",
    "        try:\n",
    "            output = int(num[0])\n",
    "            return output\n",
    "        except Exception as e:\n",
    "            print(\"failed to parse number\", e, num_str, text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate the training and test datasets\n",
    "1. Generate features like sentiment score, sentiment label, comments, likes, retweets using the above helper function.\n",
    "2. Generate label using the label helper function.\n",
    "3. Write 1 and 2 to a csv\n",
    "4. Split the data to training and test datasets following 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrease by 1% 7395.8 7304.49\n",
      "increase by 1% 7571.11 7666.67\n",
      "increase by 1% 7583.07 7680.0\n",
      "decrease by 1% 10045.42 9794.18\n",
      "decrease by 1% 7770.51 7687.46\n",
      "decrease by 1% 5298.31 5223.57\n",
      "decrease by 1% 5280.78 5226.67\n",
      "decrease by 1% 5335.31 5261.17\n",
      "decrease by 1% 5410.08 5352.02\n",
      "increase by 1% 4930.51 4991.3\n",
      "decrease by 1% 6399.82 6166.66\n",
      "increase by 1% 5083.46 5141.89\n",
      "decrease by 1% 5395.94 5323.19\n",
      "increase by 1% 6297.9 6374.35\n",
      "increase by 1% 5310.3 5367.72\n",
      "decrease by 1% 4979.59 4928.06\n",
      "decrease by 1% 6266.89 6123.6\n",
      "increase by 1% 6091.6 6203.59\n",
      "increase by 1% 5804.23 5868.47\n",
      "increase by 1% 5821.4 5898.61\n",
      "increase by 1% 5788.63 5868.74\n",
      "increase by 1% 5874.42 5946.62\n",
      "increase by 1% 6457.41 6524.62\n",
      "increase by 1% 6902.66 7090.17\n",
      "increase by 1% 9823.68 9940.94\n",
      "decrease by 1% 8710.69 8607.92\n",
      "decrease by 1% 9368.13 9262.9\n",
      "increase by 1% 9814.98 9925.94\n",
      "increase by 1% 9803.97 9931.66\n",
      "decrease by 1% 9925.0 9806.2\n",
      "increase by 1% 10165.72 10286.75\n",
      "increase by 1% 10573.31 10744.59\n",
      "increase by 1% 11057.77 11187.54\n",
      "increase by 1% 17789.02 18000.39\n",
      "increase by 1% 17468.49 17643.49\n",
      "increase by 1% 17662.18 17877.57\n",
      "decrease by 1% 23291.01 22733.1\n",
      "increase by 1% 22353.76 22619.0\n",
      "decrease by 1% 23069.61 22836.99\n",
      "increase by 1% 26889.94 27471.05\n",
      "decrease by 1% 28835.66 28488.05\n",
      "increase by 1% 38102.64 38505.82\n",
      "increase by 1% 38715.26 39160.01\n",
      "increase by 1% 37516.92 38005.72\n",
      "increase by 1% 38360.24 38790.02\n",
      "increase by 1% 38419.79 39085.45\n",
      "increase by 1% 40159.99 40696.06\n",
      "decrease by 1% 31956.92 31433.93\n",
      "increase by 1% 36686.76 38443.98\n",
      "decrease by 1% 35023.44 34559.07\n",
      "increase by 1% 36600.0 37815.53\n",
      "decrease by 1% 34736.42 34370.36\n",
      "decrease by 1% 32221.93 31688.71\n",
      "increase by 1% 34165.73 34705.7\n",
      "increase by 1% 31852.42 32325.96\n",
      "increase by 1% 32908.21 33432.52\n",
      "decrease by 1% 34270.4 33910.97\n",
      "increase by 1% 36453.34 37223.4\n",
      "decrease by 1% 37404.62 36954.41\n",
      "decrease by 1% 38315.02 37852.49\n",
      "increase by 1% 36190.0 36616.77\n",
      "decrease by 1% 38507.3 37991.05\n",
      "decrease by 1% 31220.66 30904.65\n",
      "decrease by 1% 31220.66 30904.65\n",
      "increase by 1% 29591.21 29889.03\n",
      "increase by 1% 32899.63 33264.2\n",
      "increase by 1% 30745.79 31090.01\n",
      "increase by 1% 32278.73 32603.31\n",
      "increase by 1% 32278.73 32603.31\n",
      "increase by 1% 34223.23 34663.87\n",
      "decrease by 1% 33085.89 32642.84\n",
      "increase by 1% 36992.67 37366.22\n",
      "increase by 1% 38724.69 39187.5\n",
      "decrease by 1% 48325.99 47152.38\n",
      "increase by 1% 47130.6 47741.33\n",
      "increase by 1% 54958.44 55597.96\n",
      "increase by 1% 53416.2 53993.23\n",
      "increase by 1% 45940.4 46600.0\n",
      "increase by 1% 46650.49 47282.11\n",
      "decrease by 1% 50431.67 49599.98\n",
      "increase by 1% 45865.22 46400.0\n",
      "increase by 1% 45410.24 46314.24\n",
      "increase by 1% 45543.35 46184.58\n",
      "decrease by 1% 51008.23 50492.0\n",
      "decrease by 1% 57312.68 56576.34\n",
      "increase by 1% 54889.52 55535.23\n",
      "decrease by 1% 55212.08 54613.74\n",
      "increase by 1% 54781.0 55419.98\n",
      "decrease by 1% 54200.01 53386.68\n",
      "increase by 1% 53800.96 54786.76\n",
      "decrease by 1% 59496.74 58834.3\n",
      "decrease by 1% 51901.36 50568.4\n",
      "increase by 1% 49318.65 49931.92\n",
      "increase by 1% 54890.51 55833.33\n",
      "decrease by 1% 56840.05 56071.37\n",
      "decrease by 1% 54681.13 52493.32\n",
      "decrease by 1% 46780.54 45784.9\n",
      "increase by 1% 42779.85 44742.57\n",
      "decrease by 1% 47031.76 46549.8\n",
      "decrease by 1% 47017.39 46051.38\n",
      "decrease by 1% 47308.95 46776.52\n",
      "decrease by 1% 45899.65 45073.44\n",
      "increase by 1% 39786.14 40227.22\n",
      "increase by 1% 36622.84 37161.01\n",
      "increase by 1% 39323.28 39946.37\n",
      "increase by 1% 37237.42 37610.21\n",
      "decrease by 1% 39926.63 39315.91\n",
      "increase by 1% 37000.0 37620.0\n",
      "decrease by 1% 36104.4 35678.96\n",
      "increase by 1% 39323.28 39946.37\n",
      "decrease by 1% 42556.55 41390.11\n",
      "decrease by 1% 40078.86 39622.83\n",
      "increase by 1% 37138.74 37753.87\n",
      "decrease by 1% 42610.25 42179.83\n",
      "increase by 1% 34907.37 36912.49\n",
      "increase by 1% 40326.62 41343.59\n",
      "decrease by 1% 36344.68 35939.53\n",
      "decrease by 1% 39784.97 39332.0\n",
      "increase by 1% 41793.87 42250.01\n",
      "increase by 1% 37979.01 39511.0\n",
      "increase by 1% 39150.36 39639.67\n",
      "increase by 1% 35807.91 36792.7\n",
      "increase by 1% 33548.86 33932.0\n",
      "increase by 1% 35802.81 36938.84\n",
      "decrease by 1% 36383.87 35802.81\n",
      "decrease by 1% 35731.57 35042.42\n",
      "decrease by 1% 35874.48 35500.0\n",
      "decrease by 1% 37658.99 37168.21\n",
      "increase by 1% 36160.87 36664.67\n",
      "increase by 1% 35533.66 35925.68\n",
      "increase by 1% 35533.66 35925.68\n",
      "increase by 1% 34970.31 35342.86\n",
      "decrease by 1% 33862.19 33511.91\n",
      "increase by 1% 34606.91 35192.0\n",
      "increase by 1% 34831.0 35418.63\n",
      "decrease by 1% 33848.0 33444.44\n",
      "decrease by 1% 32533.15 32174.29\n",
      "increase by 1% 30332.41 30676.38\n",
      "increase by 1% 37588.97 38051.82\n",
      "increase by 1% 40239.99 40963.22\n",
      "increase by 1% 41245.39 41778.56\n",
      "decrease by 1% 47336.41 46762.4\n",
      "increase by 1% 47499.95 48002.23\n",
      "increase by 1% 46639.2 47116.56\n",
      "decrease by 1% 45157.08 44584.12\n",
      "decrease by 1% 46074.6 45334.99\n",
      "increase by 1% 40865.33 41904.26\n",
      "increase by 1% 41151.4 41970.93\n",
      "increase by 1% 53982.81 54667.42\n",
      "increase by 1% 54058.4 54606.62\n",
      "decrease by 1% 61777.76 61044.98\n",
      "increase by 1% 64325.98 65151.46\n",
      "increase by 1% 65007.68 65895.08\n",
      "increase by 1% 59218.92 59832.58\n",
      "decrease by 1% 62705.18 62027.09\n",
      "decrease by 1% 57330.99 56341.08\n",
      "increase by 1% 56243.98 56862.4\n",
      "decrease by 1% 57134.75 56360.27\n",
      "decrease by 1% 55993.99 55387.3\n",
      "decrease by 1% 55877.0 55168.33\n",
      "decrease by 1% 55860.74 55268.6\n",
      "decrease by 1% 47251.0 46700.0\n",
      "decrease by 1% 35933.5 35567.11\n",
      "decrease by 1% 38039.34 37589.23\n",
      "increase by 1% 42655.31 43583.36\n",
      "decrease by 1% 44493.95 43977.04\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../data/elon-tweets-with-price.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['sentiment_score'], data['sentiment_label'] = zip(*data['text'].apply(get_sentiment_score_and_label))\n",
    "data['Comments'] = data.apply(lambda row: preprocess_number(str(row['Comments']), row['text']), axis=1)\n",
    "data['Likes'] = data.apply(lambda row: preprocess_number(str(row['Likes']), row['text']), axis=1)\n",
    "data['Retweets'] = data.apply(lambda row: preprocess_number(str(row['Retweets']), row['text']), axis=1)\n",
    "data['price_trend_label'] = data['next_15min_prices'].apply(get_price_trend_label)\n",
    "\n",
    "features = ['sentiment_score', 'sentiment_label', 'Comments', 'Likes', 'Retweets']\n",
    "target = 'price_trend_label'\n",
    "\n",
    "features_target_data = data[features + [target]]\n",
    "features_target_data.to_csv(\"../../data/elon-tweets-features-n-labels.csv\", index=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the distribution of the price_trend_label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "price_trend_label\n",
      " 0    4235\n",
      " 1      74\n",
      "-1      58\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set:\n",
      "price_trend_label\n",
      " 0    1058\n",
      " 1      21\n",
      "-1      13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the distribution of values in the price_trend_label column in the training set\n",
    "print(\"Training Set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Display the distribution of values in the price_trend_label column in the test set\n",
    "print(\"\\nTest Set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use logistic Regression to train the Bitcoin Price Trend Prediction model\n",
    "1. Normalize the input features since they contain values in different dimension.\n",
    "2. Use Logistic Regression with class_weight=balanced to give more importance to classes 1 and -1 which has very little data.\n",
    "3. Evaluate the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4267399267399267\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.02      0.54      0.03        13\n",
      "           0       0.97      0.43      0.60      1058\n",
      "           1       0.01      0.10      0.02        21\n",
      "\n",
      "    accuracy                           0.43      1092\n",
      "   macro avg       0.33      0.36      0.22      1092\n",
      "weighted avg       0.94      0.43      0.58      1092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# give more importance to the minority classes\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
